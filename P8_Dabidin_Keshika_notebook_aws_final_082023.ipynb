{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5a52da-3e15-4855-b5ef-e0a8565d4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab95c723-0530-4037-be2c-5c8f141c3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%info` not found.\n"
     ]
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8d0dc-3530-4597-97b3-4bbb0e53abc9",
   "metadata": {},
   "source": [
    "# Importation des librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e42e65-634f-4e2e-957d-ae0758896519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, lit, col, pandas_udf, PandasUDFType, element_at, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5493d-ed46-4ce2-8490-a44f06a00513",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d75cfb2-dbd2-4631-a7b4-aaf4e3659f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 's3://p8-data'\n",
    "PATH_Data = PATH+'/Test'\n",
    "PATH_Result = PATH+'/Results'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d8f51-1d12-417c-82da-2f3b325a7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963333a0-b96a-42c2-b2c3-32557a8beb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67253c-a33b-48bd-9425-eadad7e88e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conservation des labels\n",
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05c326c-a13a-4af3-8379-5d69a4a1cf53",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69a37c-cae4-43b3-aa68-3ad2eabaca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5a7fe-9093-4a2a-8a95-c322e7165fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a5c34-8b5b-453f-a3d3-b6b05e77e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187f488-1d16-4b24-8f42-5fe11eb522d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388dd79c-8f9a-4d7d-afcf-8a80f942b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21aee1-d895-4d26-b1b8-28655f78729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21bcca-96f7-499f-895d-d1e3e8c60df8",
   "metadata": {},
   "source": [
    "# Extraction des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602e2742-5b22-4046-8c95-bad0b43decb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe887b5c-ab6a-4fe5-9565-30fe33f76d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = images.repartition(24).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a8a51-37ef-4ec4-aaaa-63de26bb926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80845f3-3ce6-4769-866a-cba902272e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcd7ba-f667-4262-8f65-62d72cfb6227",
   "metadata": {},
   "source": [
    "# Réduction de dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb0fcb-9d0a-44f8-b871-6736f03e2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, DenseVector\n",
    "\n",
    "def preprocess(dataframe):\n",
    "  '''\n",
    "     opérations à effectuer :\n",
    "     - features sont de type array, il faudra la convertir en vecteur dense\n",
    "     - standardisation\n",
    "    \n",
    "  '''\n",
    "  \n",
    "  # conversion des données images en vecteur dense\n",
    "  transform_vecteur_dense = udf(lambda r: Vectors.dense(r), VectorUDT())\n",
    "  dataframe = dataframe.withColumn('features_vectors', transform_vecteur_dense('features'))\n",
    "  # Standardisation \n",
    "  scaler_std = StandardScaler(inputCol=\"features_vectors\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "  model_std = scaler_std.fit(dataframe)\n",
    "  # Mise à l'échelle\n",
    "  dataframe = model_std.transform(dataframe)\n",
    "  \n",
    "  return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5897fe9-c184-4a2e-b2c0-9d23552e7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recherche du nombre de composante expliquant 95% de la variance\n",
    "def nb_composante(dataframe, nb_comp=100):\n",
    "    pca = PCA(k = nb_comp,\n",
    "              inputCol=\"features_scaled\", \n",
    "              outputCol=\"features_pca\")\n",
    " \n",
    "    model_pca = pca.fit(dataframe)\n",
    "    variance = model_pca.explainedVariance\n",
    " \n",
    "    for i in range(100):\n",
    "        a = variance.cumsum()[i]\n",
    "        if a >= 0.95:\n",
    "            print(\"{} composantes principales expliquent au moins 95% de la variance totale\".format(i))\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0081ae-d565-482a-8551-fdfc62654314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processing (vecteur dense, standardisation)\n",
    "df_preprocess = preprocess(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8918945-bea7-4820-9619-b67705f187c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de composante expliquant 95% de la variance\n",
    "nombre_cp = nb_composante(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd1cca-efa2-4747-b163-66726f21d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de dimension PCA\n",
    "# Entrainement de l'algorithme\n",
    "pca = PCA(k=nombre_cp, inputCol='features_scaled', outputCol='vectors_pca')\n",
    "action_pca = pca.fit(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25496a-28a8-4f80-807f-a5e6cf1106cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des images sur les k premières composantes\n",
    "df_final= action_pca.transform(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82801845-33c7-4e20-aaae-eb77bf55c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e74208-5d87-469f-8850-b9e88adf9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cbe203-353b-46ca-8ca6-f8d009c9f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceab91e-b28a-43d9-8d00-4c3f3950a65f",
   "metadata": {},
   "source": [
    "# Validation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f626568-ec1e-4812-a311-edb7b1775bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cc4ad-9d30-49fb-bb92-26125f6b0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2261b-f498-49f6-9866-ce6141f3fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e641d4-e514-43a4-9b0f-ce283c4d3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
